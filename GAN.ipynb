{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv9yXefyZbC/Ofi1SxZoJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/statrav/pages/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OYasyAz8TiIA"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리 import\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# latent_vector를 뽑기 위한 noise 분포의 dimension(차원)\n",
        "latent_dim = 100"
      ],
      "metadata": {
        "id": "1DE3z5NfXKdI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator(생성자) 클래스\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Generator, self).__init__()\n",
        "\n",
        "      # 하나의 블록(block) 정의 → 이러한 블록을 원하는만큼 쌓아 사용할 수 있도록 함수 정의\n",
        "      def block(input_dim, output_dim, normalize = True):\n",
        "        layers = [nn.Linear(input_dim, output_dim)] # 하나의 블록에서는 하나의 선형 함수를 거침\n",
        "        if normalize:\n",
        "          layers.append(nn.BatchNorm1d(output_dim, 0.8)) # 배치 정규화 (Batch Normalization) 수행 - 차원 동일\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace = True)) # Activation 함수로 LeakyReLU 선택\n",
        "        return layers\n",
        "\n",
        "      # 생성자 모델은 연속적인 여러개의 블록을 가짐\n",
        "      self.model = nn.Sequential(\n",
        "          *block(latent_dim, 128, normalize = False),\n",
        "          *block(128, 256),\n",
        "          *block(256, 512),\n",
        "          *block(512, 1024),\n",
        "          nn.Linear(1024, 1 * 28 * 28), # 결과적으로 (1*28*28)짜리 MNIST data를 생성\n",
        "          nn.Tanh() # 탄젠트를 붙여서 (-1, 1)사이의 값을 가질 수 있도록 함\n",
        "      )\n",
        "\n",
        "    def forward(self, z): # 하나의 noise_vector z를 model에 넣음\n",
        "      img = self.model(z)\n",
        "      img = img.view(img.size(0), 1, 28, 28) # 이미지 형태 → batch size : img.size(0) / channel : 1 / height : 28 / width : 28\n",
        "      return img"
      ],
      "metadata": {
        "id": "1eEtavv2Xnje"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator(판별자) 클래스\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(1 * 28 * 28, 512), # 한 장의 이미지가 들어옴\n",
        "      nn.LeakyReLU(0.2, inplace=True), # 그 이미지를 판별하기 위해 여러 개의 Linear와 Activation Function을 사용\n",
        "      nn.Linear(512, 256),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Linear(256, 1),\n",
        "      nn.Sigmoid(), # 결과적으로 sigmoid 함수로 확률값을 내보냄\n",
        "    )\n",
        "\n",
        "  # 이미지에 대한 판별 결과 반환\n",
        "  def forward(self, img):\n",
        "    flattened = img.view(img.size(0), -1) # 이미지가 input되면, flattened를 통해 vector 형태로 나열\n",
        "    output = self.model(flattened) # vector_img를 model에 넣어 확률 추출\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "KG6NNktuZ7hA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 Dataset 불러오기 - MNIST Dataset\n",
        "\n",
        "# 이미지 전처리(변형) 함수\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize(28), # 크기 : 28*28\n",
        "    transforms.ToTensor(), # PyTorch의 Tensor 형태\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4) # 하나의 batch에 포함되어 있는 이미지가 128개가 되도록 설정"
      ],
      "metadata": {
        "id": "MHnkVqwcbOVj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# G, D class 초기화\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "0jSIPdnibx06"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU로 올리기\n",
        "generator.cuda()\n",
        "discriminator.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP2cAxMeb5Qr",
        "outputId": "b5e311a1-0662-4fd4-9453-65bac448045f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 (loss function)\n",
        "adversarial_loss = nn.BCELoss() # BCE 손실함수 선택\n",
        "adversarial_loss.cuda() # GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZEICmMqcblO",
        "outputId": "86d5f4d2-a7a5-4118-c786-ea7cdaad2fe7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습률(learning rate) 설정\n",
        "lr = 0.0002 # 일반적으로 가장 많이 사용되는 하이퍼 파라미터 값 사용 (0.0002)"
      ],
      "metadata": {
        "id": "U-iPGhn3cmN7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적화 함수 선택 - Adam Optimizer\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999)) # 일반적으로 가장 많이 사용되는 beta 하이퍼 파라미터 값 사용 (0.0002)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "_JNhY9-HcqHx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
        "sample_interval = 2000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
        "        # 매 batch에 포함되어 있는 이미지의 개수(imgs.size(0))만큼 real label과 fake label을 만들어서 학습을 위한 label로 사용\n",
        "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
        "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
        "\n",
        "        real_imgs = imgs.cuda()\n",
        "\n",
        "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # 랜덤 노이즈(noise) 샘플링 : 이미지의 개수(imgs.shape[0])만큼 noise 생성\n",
        "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
        "\n",
        "        # 이미지 생성\n",
        "        generated_imgs = generator(z)\n",
        "\n",
        "        # 생성자(generator)의 손실(loss) 값 계산\n",
        "        # 생성자가 만든 이미지가 discriminator에 의해서 real로 학습되도록 진행\n",
        "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
        "\n",
        "        # 생성자(generator) 업데이트\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
        "        # 판별자는 real은 real로 fake는 fake로 학습하도록 진행\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
        "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2 # 학습이 잘 되면, Discriminator는 더이상 real과 fake를 구분해낼 수 없기 때문에 항상 50% 라는 확률만 나오게 됨\n",
        "\n",
        "        # 판별자(discriminator) 업데이트\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        done = epoch * len(dataloader) + i\n",
        "        if done % sample_interval == 0:\n",
        "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
        "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
        "\n",
        "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
        "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNhkw8BScxhB",
        "outputId": "8d106c6b-5682-415f-876d-48bf4ec30862"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/200] [D loss: 0.471526] [G loss: 1.283353] [Elapsed time: 17.21s]\n",
            "[Epoch 1/200] [D loss: 0.448029] [G loss: 1.956092] [Elapsed time: 32.81s]\n",
            "[Epoch 2/200] [D loss: 0.303868] [G loss: 1.939445] [Elapsed time: 46.91s]\n",
            "[Epoch 3/200] [D loss: 0.310527] [G loss: 1.459419] [Elapsed time: 60.99s]\n",
            "[Epoch 4/200] [D loss: 0.322743] [G loss: 2.100187] [Elapsed time: 76.28s]\n",
            "[Epoch 5/200] [D loss: 0.500441] [G loss: 0.603843] [Elapsed time: 90.46s]\n",
            "[Epoch 6/200] [D loss: 0.276533] [G loss: 2.039906] [Elapsed time: 104.65s]\n",
            "[Epoch 7/200] [D loss: 0.259627] [G loss: 1.213598] [Elapsed time: 118.96s]\n",
            "[Epoch 8/200] [D loss: 0.272050] [G loss: 1.132115] [Elapsed time: 133.22s]\n",
            "[Epoch 9/200] [D loss: 0.481293] [G loss: 0.601572] [Elapsed time: 147.27s]\n",
            "[Epoch 10/200] [D loss: 0.254769] [G loss: 1.050612] [Elapsed time: 161.51s]\n",
            "[Epoch 11/200] [D loss: 0.247693] [G loss: 1.169346] [Elapsed time: 175.84s]\n",
            "[Epoch 12/200] [D loss: 1.229607] [G loss: 6.536437] [Elapsed time: 190.19s]\n",
            "[Epoch 13/200] [D loss: 0.613118] [G loss: 4.484550] [Elapsed time: 204.52s]\n",
            "[Epoch 14/200] [D loss: 0.741274] [G loss: 4.339169] [Elapsed time: 218.91s]\n",
            "[Epoch 15/200] [D loss: 0.150533] [G loss: 2.977509] [Elapsed time: 233.20s]\n",
            "[Epoch 16/200] [D loss: 0.252918] [G loss: 1.415968] [Elapsed time: 247.21s]\n",
            "[Epoch 17/200] [D loss: 0.474591] [G loss: 3.764102] [Elapsed time: 261.15s]\n",
            "[Epoch 18/200] [D loss: 0.173643] [G loss: 1.682659] [Elapsed time: 275.26s]\n",
            "[Epoch 19/200] [D loss: 0.224225] [G loss: 4.369302] [Elapsed time: 290.41s]\n",
            "[Epoch 20/200] [D loss: 0.314940] [G loss: 2.432450] [Elapsed time: 304.74s]\n",
            "[Epoch 21/200] [D loss: 0.159355] [G loss: 2.244903] [Elapsed time: 319.03s]\n",
            "[Epoch 22/200] [D loss: 0.241022] [G loss: 2.282614] [Elapsed time: 333.62s]\n",
            "[Epoch 23/200] [D loss: 0.212811] [G loss: 1.826060] [Elapsed time: 348.01s]\n",
            "[Epoch 24/200] [D loss: 0.289074] [G loss: 1.454844] [Elapsed time: 362.36s]\n",
            "[Epoch 25/200] [D loss: 0.217086] [G loss: 1.278423] [Elapsed time: 376.49s]\n",
            "[Epoch 26/200] [D loss: 0.121384] [G loss: 2.499202] [Elapsed time: 390.60s]\n",
            "[Epoch 27/200] [D loss: 0.355153] [G loss: 5.490287] [Elapsed time: 404.51s]\n",
            "[Epoch 28/200] [D loss: 0.153989] [G loss: 2.223441] [Elapsed time: 418.73s]\n",
            "[Epoch 29/200] [D loss: 0.191706] [G loss: 2.059844] [Elapsed time: 432.93s]\n",
            "[Epoch 30/200] [D loss: 0.463271] [G loss: 2.970522] [Elapsed time: 447.13s]\n",
            "[Epoch 31/200] [D loss: 0.361404] [G loss: 3.188327] [Elapsed time: 461.19s]\n",
            "[Epoch 32/200] [D loss: 0.513503] [G loss: 4.150552] [Elapsed time: 475.29s]\n",
            "[Epoch 33/200] [D loss: 0.247556] [G loss: 1.486623] [Elapsed time: 489.51s]\n",
            "[Epoch 34/200] [D loss: 0.168149] [G loss: 2.472760] [Elapsed time: 504.67s]\n",
            "[Epoch 35/200] [D loss: 0.165554] [G loss: 2.523287] [Elapsed time: 518.87s]\n",
            "[Epoch 36/200] [D loss: 0.260187] [G loss: 3.150482] [Elapsed time: 532.92s]\n",
            "[Epoch 37/200] [D loss: 0.307666] [G loss: 3.109070] [Elapsed time: 547.09s]\n",
            "[Epoch 38/200] [D loss: 0.510743] [G loss: 0.842172] [Elapsed time: 561.22s]\n",
            "[Epoch 39/200] [D loss: 0.295697] [G loss: 3.254383] [Elapsed time: 576.13s]\n",
            "[Epoch 40/200] [D loss: 0.278667] [G loss: 2.674669] [Elapsed time: 590.94s]\n",
            "[Epoch 41/200] [D loss: 0.325985] [G loss: 4.443310] [Elapsed time: 606.24s]\n",
            "[Epoch 42/200] [D loss: 0.247773] [G loss: 2.577389] [Elapsed time: 620.17s]\n",
            "[Epoch 43/200] [D loss: 0.232937] [G loss: 1.641578] [Elapsed time: 634.23s]\n",
            "[Epoch 44/200] [D loss: 0.375674] [G loss: 3.307792] [Elapsed time: 648.46s]\n",
            "[Epoch 45/200] [D loss: 0.188909] [G loss: 2.052774] [Elapsed time: 662.62s]\n",
            "[Epoch 46/200] [D loss: 0.203492] [G loss: 2.003269] [Elapsed time: 676.74s]\n",
            "[Epoch 47/200] [D loss: 0.266058] [G loss: 1.743113] [Elapsed time: 690.98s]\n",
            "[Epoch 48/200] [D loss: 0.310638] [G loss: 3.897310] [Elapsed time: 706.18s]\n",
            "[Epoch 49/200] [D loss: 0.209928] [G loss: 1.961552] [Elapsed time: 720.09s]\n",
            "[Epoch 50/200] [D loss: 0.157510] [G loss: 3.201635] [Elapsed time: 733.96s]\n",
            "[Epoch 51/200] [D loss: 0.327016] [G loss: 1.129468] [Elapsed time: 747.81s]\n",
            "[Epoch 52/200] [D loss: 0.291801] [G loss: 3.480786] [Elapsed time: 762.02s]\n",
            "[Epoch 53/200] [D loss: 0.201460] [G loss: 2.447472] [Elapsed time: 775.91s]\n",
            "[Epoch 54/200] [D loss: 0.213075] [G loss: 1.855648] [Elapsed time: 789.99s]\n",
            "[Epoch 55/200] [D loss: 0.275437] [G loss: 2.127868] [Elapsed time: 804.00s]\n",
            "[Epoch 56/200] [D loss: 0.301087] [G loss: 1.854451] [Elapsed time: 818.19s]\n",
            "[Epoch 57/200] [D loss: 0.325191] [G loss: 1.381258] [Elapsed time: 832.29s]\n",
            "[Epoch 58/200] [D loss: 0.333008] [G loss: 1.668038] [Elapsed time: 846.63s]\n",
            "[Epoch 59/200] [D loss: 0.266961] [G loss: 1.818689] [Elapsed time: 860.61s]\n",
            "[Epoch 60/200] [D loss: 0.375475] [G loss: 1.090885] [Elapsed time: 874.48s]\n",
            "[Epoch 61/200] [D loss: 0.216315] [G loss: 2.318814] [Elapsed time: 888.33s]\n",
            "[Epoch 62/200] [D loss: 0.287893] [G loss: 2.328172] [Elapsed time: 902.08s]\n",
            "[Epoch 63/200] [D loss: 0.254470] [G loss: 2.076807] [Elapsed time: 917.06s]\n",
            "[Epoch 64/200] [D loss: 0.217887] [G loss: 1.968341] [Elapsed time: 930.83s]\n",
            "[Epoch 65/200] [D loss: 0.636002] [G loss: 3.793685] [Elapsed time: 944.85s]\n",
            "[Epoch 66/200] [D loss: 0.221646] [G loss: 2.160340] [Elapsed time: 958.90s]\n",
            "[Epoch 67/200] [D loss: 0.318121] [G loss: 2.662343] [Elapsed time: 972.93s]\n",
            "[Epoch 68/200] [D loss: 0.399006] [G loss: 3.979323] [Elapsed time: 986.77s]\n",
            "[Epoch 69/200] [D loss: 0.317469] [G loss: 2.174162] [Elapsed time: 1000.43s]\n",
            "[Epoch 70/200] [D loss: 0.236079] [G loss: 1.740166] [Elapsed time: 1014.14s]\n",
            "[Epoch 71/200] [D loss: 0.172881] [G loss: 2.110918] [Elapsed time: 1028.05s]\n",
            "[Epoch 72/200] [D loss: 0.263759] [G loss: 1.588660] [Elapsed time: 1041.92s]\n",
            "[Epoch 73/200] [D loss: 0.223864] [G loss: 2.312205] [Elapsed time: 1055.71s]\n",
            "[Epoch 74/200] [D loss: 0.233226] [G loss: 1.696056] [Elapsed time: 1069.58s]\n",
            "[Epoch 75/200] [D loss: 0.390298] [G loss: 1.068301] [Elapsed time: 1083.33s]\n",
            "[Epoch 76/200] [D loss: 0.204308] [G loss: 2.028693] [Elapsed time: 1097.29s]\n",
            "[Epoch 77/200] [D loss: 0.242412] [G loss: 2.138375] [Elapsed time: 1112.04s]\n",
            "[Epoch 78/200] [D loss: 0.366556] [G loss: 3.813409] [Elapsed time: 1125.88s]\n",
            "[Epoch 79/200] [D loss: 0.252876] [G loss: 2.386566] [Elapsed time: 1139.63s]\n",
            "[Epoch 80/200] [D loss: 0.220916] [G loss: 2.132913] [Elapsed time: 1153.57s]\n",
            "[Epoch 81/200] [D loss: 0.319772] [G loss: 1.374111] [Elapsed time: 1167.42s]\n",
            "[Epoch 82/200] [D loss: 0.224399] [G loss: 1.855717] [Elapsed time: 1181.17s]\n",
            "[Epoch 83/200] [D loss: 0.220919] [G loss: 1.990988] [Elapsed time: 1194.90s]\n",
            "[Epoch 84/200] [D loss: 0.428659] [G loss: 2.535120] [Elapsed time: 1208.58s]\n",
            "[Epoch 85/200] [D loss: 0.248890] [G loss: 2.047983] [Elapsed time: 1222.47s]\n",
            "[Epoch 86/200] [D loss: 0.320136] [G loss: 2.489528] [Elapsed time: 1236.28s]\n",
            "[Epoch 87/200] [D loss: 0.295070] [G loss: 1.619066] [Elapsed time: 1250.13s]\n",
            "[Epoch 88/200] [D loss: 0.299930] [G loss: 1.308267] [Elapsed time: 1264.12s]\n",
            "[Epoch 89/200] [D loss: 0.305441] [G loss: 1.889849] [Elapsed time: 1278.04s]\n",
            "[Epoch 90/200] [D loss: 0.283943] [G loss: 1.650602] [Elapsed time: 1292.00s]\n",
            "[Epoch 91/200] [D loss: 0.260650] [G loss: 1.811952] [Elapsed time: 1306.13s]\n",
            "[Epoch 92/200] [D loss: 0.290651] [G loss: 1.830854] [Elapsed time: 1321.24s]\n",
            "[Epoch 93/200] [D loss: 0.719371] [G loss: 0.483319] [Elapsed time: 1335.20s]\n",
            "[Epoch 94/200] [D loss: 0.309317] [G loss: 1.902816] [Elapsed time: 1348.99s]\n",
            "[Epoch 95/200] [D loss: 0.316992] [G loss: 1.715443] [Elapsed time: 1362.83s]\n",
            "[Epoch 96/200] [D loss: 0.278397] [G loss: 1.627100] [Elapsed time: 1376.86s]\n",
            "[Epoch 97/200] [D loss: 0.263153] [G loss: 1.585461] [Elapsed time: 1390.76s]\n",
            "[Epoch 98/200] [D loss: 0.309653] [G loss: 1.537892] [Elapsed time: 1405.00s]\n",
            "[Epoch 99/200] [D loss: 0.235708] [G loss: 2.004326] [Elapsed time: 1418.81s]\n",
            "[Epoch 100/200] [D loss: 0.280172] [G loss: 2.465441] [Elapsed time: 1432.66s]\n",
            "[Epoch 101/200] [D loss: 0.233338] [G loss: 1.940632] [Elapsed time: 1446.42s]\n",
            "[Epoch 102/200] [D loss: 0.178591] [G loss: 2.187105] [Elapsed time: 1460.33s]\n",
            "[Epoch 103/200] [D loss: 0.308064] [G loss: 1.596663] [Elapsed time: 1474.14s]\n",
            "[Epoch 104/200] [D loss: 0.275345] [G loss: 1.809423] [Elapsed time: 1488.00s]\n",
            "[Epoch 105/200] [D loss: 0.226026] [G loss: 2.474714] [Elapsed time: 1501.75s]\n",
            "[Epoch 106/200] [D loss: 0.489821] [G loss: 1.085891] [Elapsed time: 1516.76s]\n",
            "[Epoch 107/200] [D loss: 0.342971] [G loss: 1.458578] [Elapsed time: 1530.50s]\n",
            "[Epoch 108/200] [D loss: 0.288240] [G loss: 2.536331] [Elapsed time: 1544.34s]\n",
            "[Epoch 109/200] [D loss: 0.229196] [G loss: 2.151156] [Elapsed time: 1558.20s]\n",
            "[Epoch 110/200] [D loss: 0.287630] [G loss: 1.572901] [Elapsed time: 1572.16s]\n",
            "[Epoch 111/200] [D loss: 0.293229] [G loss: 2.519717] [Elapsed time: 1586.03s]\n",
            "[Epoch 112/200] [D loss: 0.171607] [G loss: 2.226896] [Elapsed time: 1599.72s]\n",
            "[Epoch 113/200] [D loss: 0.218295] [G loss: 2.538217] [Elapsed time: 1613.44s]\n",
            "[Epoch 114/200] [D loss: 0.333163] [G loss: 3.250265] [Elapsed time: 1627.26s]\n",
            "[Epoch 115/200] [D loss: 0.329613] [G loss: 2.497141] [Elapsed time: 1640.99s]\n",
            "[Epoch 116/200] [D loss: 0.319284] [G loss: 3.548800] [Elapsed time: 1654.68s]\n",
            "[Epoch 117/200] [D loss: 0.255337] [G loss: 2.629170] [Elapsed time: 1668.27s]\n",
            "[Epoch 118/200] [D loss: 0.258010] [G loss: 2.567099] [Elapsed time: 1682.09s]\n",
            "[Epoch 119/200] [D loss: 0.327473] [G loss: 1.803854] [Elapsed time: 1695.83s]\n",
            "[Epoch 120/200] [D loss: 0.216617] [G loss: 2.170823] [Elapsed time: 1709.66s]\n",
            "[Epoch 121/200] [D loss: 0.326356] [G loss: 4.209793] [Elapsed time: 1724.45s]\n",
            "[Epoch 122/200] [D loss: 0.325460] [G loss: 2.486729] [Elapsed time: 1738.34s]\n",
            "[Epoch 123/200] [D loss: 0.383334] [G loss: 3.094441] [Elapsed time: 1752.08s]\n",
            "[Epoch 124/200] [D loss: 0.274399] [G loss: 2.328918] [Elapsed time: 1765.69s]\n",
            "[Epoch 125/200] [D loss: 0.225727] [G loss: 3.250928] [Elapsed time: 1779.32s]\n",
            "[Epoch 126/200] [D loss: 0.153607] [G loss: 3.220753] [Elapsed time: 1793.28s]\n",
            "[Epoch 127/200] [D loss: 0.283576] [G loss: 3.362550] [Elapsed time: 1807.08s]\n",
            "[Epoch 128/200] [D loss: 0.270669] [G loss: 2.251508] [Elapsed time: 1820.91s]\n",
            "[Epoch 129/200] [D loss: 0.221724] [G loss: 2.160290] [Elapsed time: 1834.59s]\n",
            "[Epoch 130/200] [D loss: 0.309134] [G loss: 1.797868] [Elapsed time: 1848.54s]\n",
            "[Epoch 131/200] [D loss: 0.216622] [G loss: 2.402347] [Elapsed time: 1862.41s]\n",
            "[Epoch 132/200] [D loss: 0.191897] [G loss: 2.636866] [Elapsed time: 1876.48s]\n",
            "[Epoch 133/200] [D loss: 0.316956] [G loss: 1.292193] [Elapsed time: 1890.57s]\n",
            "[Epoch 134/200] [D loss: 0.250799] [G loss: 1.907880] [Elapsed time: 1904.48s]\n",
            "[Epoch 135/200] [D loss: 0.265813] [G loss: 1.973523] [Elapsed time: 1919.42s]\n",
            "[Epoch 136/200] [D loss: 0.214003] [G loss: 2.226167] [Elapsed time: 1933.48s]\n",
            "[Epoch 137/200] [D loss: 0.383253] [G loss: 2.638253] [Elapsed time: 1947.41s]\n",
            "[Epoch 138/200] [D loss: 0.316391] [G loss: 1.866401] [Elapsed time: 1961.50s]\n",
            "[Epoch 139/200] [D loss: 0.217548] [G loss: 2.223544] [Elapsed time: 1975.49s]\n",
            "[Epoch 140/200] [D loss: 0.285447] [G loss: 2.090878] [Elapsed time: 1989.49s]\n",
            "[Epoch 141/200] [D loss: 0.266087] [G loss: 1.871909] [Elapsed time: 2003.48s]\n",
            "[Epoch 142/200] [D loss: 0.169907] [G loss: 2.823432] [Elapsed time: 2017.39s]\n",
            "[Epoch 143/200] [D loss: 0.281134] [G loss: 1.930685] [Elapsed time: 2031.26s]\n",
            "[Epoch 144/200] [D loss: 0.256627] [G loss: 2.347716] [Elapsed time: 2045.13s]\n",
            "[Epoch 145/200] [D loss: 0.326755] [G loss: 2.633652] [Elapsed time: 2058.95s]\n",
            "[Epoch 146/200] [D loss: 0.367700] [G loss: 3.537898] [Elapsed time: 2072.95s]\n",
            "[Epoch 147/200] [D loss: 0.158398] [G loss: 2.614395] [Elapsed time: 2086.74s]\n",
            "[Epoch 148/200] [D loss: 0.251864] [G loss: 2.218762] [Elapsed time: 2100.73s]\n",
            "[Epoch 149/200] [D loss: 0.286081] [G loss: 3.498906] [Elapsed time: 2115.85s]\n",
            "[Epoch 150/200] [D loss: 0.228758] [G loss: 2.145846] [Elapsed time: 2129.97s]\n",
            "[Epoch 151/200] [D loss: 0.310283] [G loss: 1.375731] [Elapsed time: 2143.89s]\n",
            "[Epoch 152/200] [D loss: 0.292329] [G loss: 3.409348] [Elapsed time: 2157.65s]\n",
            "[Epoch 153/200] [D loss: 0.208433] [G loss: 1.880831] [Elapsed time: 2171.62s]\n",
            "[Epoch 154/200] [D loss: 0.273827] [G loss: 1.885045] [Elapsed time: 2185.36s]\n",
            "[Epoch 155/200] [D loss: 0.270527] [G loss: 2.401492] [Elapsed time: 2199.44s]\n",
            "[Epoch 156/200] [D loss: 0.183474] [G loss: 3.371899] [Elapsed time: 2213.48s]\n",
            "[Epoch 157/200] [D loss: 0.268463] [G loss: 1.955873] [Elapsed time: 2227.55s]\n",
            "[Epoch 158/200] [D loss: 0.329694] [G loss: 3.843770] [Elapsed time: 2241.65s]\n",
            "[Epoch 159/200] [D loss: 0.252768] [G loss: 2.026271] [Elapsed time: 2255.65s]\n",
            "[Epoch 160/200] [D loss: 0.304508] [G loss: 3.074538] [Elapsed time: 2269.58s]\n",
            "[Epoch 161/200] [D loss: 0.352781] [G loss: 2.351716] [Elapsed time: 2283.63s]\n",
            "[Epoch 162/200] [D loss: 0.255612] [G loss: 1.769839] [Elapsed time: 2298.33s]\n",
            "[Epoch 163/200] [D loss: 0.286251] [G loss: 1.509073] [Elapsed time: 2312.32s]\n",
            "[Epoch 164/200] [D loss: 0.330027] [G loss: 1.825772] [Elapsed time: 2326.29s]\n",
            "[Epoch 165/200] [D loss: 0.171259] [G loss: 2.811591] [Elapsed time: 2340.18s]\n",
            "[Epoch 166/200] [D loss: 0.198215] [G loss: 2.577905] [Elapsed time: 2354.41s]\n",
            "[Epoch 167/200] [D loss: 0.251603] [G loss: 2.408640] [Elapsed time: 2368.39s]\n",
            "[Epoch 168/200] [D loss: 0.299126] [G loss: 3.727755] [Elapsed time: 2382.29s]\n",
            "[Epoch 169/200] [D loss: 0.263202] [G loss: 2.933834] [Elapsed time: 2396.15s]\n",
            "[Epoch 170/200] [D loss: 0.247786] [G loss: 2.383110] [Elapsed time: 2410.13s]\n",
            "[Epoch 171/200] [D loss: 0.261158] [G loss: 2.224220] [Elapsed time: 2423.99s]\n",
            "[Epoch 172/200] [D loss: 0.212078] [G loss: 2.818019] [Elapsed time: 2438.03s]\n",
            "[Epoch 173/200] [D loss: 0.277687] [G loss: 2.153163] [Elapsed time: 2451.99s]\n",
            "[Epoch 174/200] [D loss: 0.214255] [G loss: 2.396790] [Elapsed time: 2465.94s]\n",
            "[Epoch 175/200] [D loss: 0.232306] [G loss: 2.063774] [Elapsed time: 2480.13s]\n",
            "[Epoch 176/200] [D loss: 0.237995] [G loss: 1.867190] [Elapsed time: 2494.95s]\n",
            "[Epoch 177/200] [D loss: 0.165844] [G loss: 2.638012] [Elapsed time: 2508.99s]\n",
            "[Epoch 178/200] [D loss: 0.214267] [G loss: 2.553843] [Elapsed time: 2523.07s]\n",
            "[Epoch 179/200] [D loss: 0.296529] [G loss: 1.464185] [Elapsed time: 2537.18s]\n",
            "[Epoch 180/200] [D loss: 0.301603] [G loss: 1.938665] [Elapsed time: 2551.07s]\n",
            "[Epoch 181/200] [D loss: 0.344025] [G loss: 3.606740] [Elapsed time: 2565.06s]\n",
            "[Epoch 182/200] [D loss: 0.266526] [G loss: 2.828118] [Elapsed time: 2578.94s]\n",
            "[Epoch 183/200] [D loss: 0.229665] [G loss: 2.746505] [Elapsed time: 2592.92s]\n",
            "[Epoch 184/200] [D loss: 0.315322] [G loss: 2.969271] [Elapsed time: 2607.00s]\n",
            "[Epoch 185/200] [D loss: 0.262607] [G loss: 2.684211] [Elapsed time: 2620.81s]\n",
            "[Epoch 186/200] [D loss: 0.322096] [G loss: 1.991238] [Elapsed time: 2634.48s]\n",
            "[Epoch 187/200] [D loss: 0.262685] [G loss: 3.121845] [Elapsed time: 2648.12s]\n",
            "[Epoch 188/200] [D loss: 0.227996] [G loss: 2.191666] [Elapsed time: 2661.81s]\n",
            "[Epoch 189/200] [D loss: 0.212642] [G loss: 2.691093] [Elapsed time: 2675.71s]\n",
            "[Epoch 190/200] [D loss: 0.281240] [G loss: 2.334331] [Elapsed time: 2691.17s]\n",
            "[Epoch 191/200] [D loss: 0.250091] [G loss: 2.531319] [Elapsed time: 2705.01s]\n",
            "[Epoch 192/200] [D loss: 0.318838] [G loss: 1.377816] [Elapsed time: 2718.97s]\n",
            "[Epoch 193/200] [D loss: 0.191652] [G loss: 2.119672] [Elapsed time: 2732.68s]\n",
            "[Epoch 194/200] [D loss: 0.359890] [G loss: 2.180470] [Elapsed time: 2746.48s]\n",
            "[Epoch 195/200] [D loss: 0.207368] [G loss: 2.508211] [Elapsed time: 2760.25s]\n",
            "[Epoch 196/200] [D loss: 0.199576] [G loss: 2.651445] [Elapsed time: 2774.09s]\n",
            "[Epoch 197/200] [D loss: 0.230306] [G loss: 2.226691] [Elapsed time: 2787.80s]\n",
            "[Epoch 198/200] [D loss: 0.252581] [G loss: 1.955855] [Elapsed time: 2801.45s]\n",
            "[Epoch 199/200] [D loss: 0.269035] [G loss: 3.286184] [Elapsed time: 2815.47s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('92000.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "v-toZVpceQR4",
        "outputId": "04125bb9-0fa2-43e9-d571-9e58b85b9cd0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}